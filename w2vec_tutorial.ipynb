{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOEqhxMNrbm5sOAxbQwN22a"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"GeG4zVAW_SPS"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","from pathlib import Path\n","\n","data_path = Path('/kaggle/input/otto-recommender-system/')"]},{"cell_type":"code","source":["def read_json(target: str) -> pd.DataFrame():\n","    sessions = pd.DataFrame()\n","    chunks = pd.read_json(data_path / f'{target}.jsonl', lines=True, chunksize=100_000)\n","\n","    for e, chunk in enumerate(chunks):\n","        event_dict = {\n","            'session': [],\n","            'aid': [],\n","            'ts': [],\n","            'type': [],\n","        }\n","        if e < 2:\n","            for session, events in zip(chunk['session'].tolist(), chunk['events'].tolist()):\n","                for event in events:\n","                    event_dict['session'].append(session)\n","                    event_dict['aid'].append(event['aid'])\n","                    event_dict['ts'].append(event['ts'])\n","                    event_dict['type'].append(event['type'])\n","            chunk_session = pd.DataFrame(event_dict)\n","            sessions = pd.concat([sessions, chunk_session])\n","        else:\n","            break\n","    return sessions.reset_index(drop=True)\n","train_sessions = read_json('train')\n","test_sessions = read_json('test')"],"metadata":{"id":"i1dDW8uu_Y9M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import hashlib\n","import os\n","from gensim.models import word2vec\n","from gensim.models import KeyedVectors\n","os.environ[\"PYTHONHASHSEED\"] = str(42)\n","def hashfxn(x):\n","    return int(hashlib.md5(str(x).encode()).hexdigest(), 16)\n","\n","from tqdm.notebook import tqdm"],"metadata":{"id":"MHA9rNSY_aR2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["raw_corpus = []\n","for session, group_df in tqdm(train_sessions.groupby(['session'])):\n","    raw_corpus.append(list(group_df['aid'].astype(str) + '_' + group_df['type']))\n","for session, group_df in tqdm(test_sessions.groupby(['session'])):\n","    raw_corpus.append(list(group_df['aid'].astype(str) + '_' + group_df['type']))"],"metadata":{"id":"Zq-ViOnL_b12"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["w2v = Word2Vec(sentences=raw_corpus, vector_size=100, window=5, min_count=1, sg=0, workers=-1, seed=42, hashfxn=hashfxn)"],"metadata":{"id":"y8yTH96y_eV4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["w2v.wv.save_word2vec_format('otto_aid2vec.bin', binary=True)"],"metadata":{"id":"h9K7dqg-_iAv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sub_list = []\n","\n","for session, group_df in tqdm(test_sessions.groupby('session')) :\n","  aid_list = []\n","  results = w2v.wv.most_similar(positive=list((group_df['aid'].astype(str) + '_'+group_df['tyep']), topn=500)\n","  for result in results :\n","    aid = result[0].split('_')[0]\n","    if aid not in aid_list:\n","            aid_list.append(aid)\n","        if len(aid_list) == 20:\n","            aid_list = ' '.join(aid_list)\n","            break\n","    sub_list.append([f'{session}_clicks', aid_list])\n","    sub_list.append([f'{session}_carts', aid_list])\n","    sub_list.append([f'{session}_orders', aid_list])"],"metadata":{"id":"OSg3G3FE_qPC"},"execution_count":null,"outputs":[]}]}