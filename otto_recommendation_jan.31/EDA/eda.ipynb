{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPnCqpMy2oEG+hkhrytI0Vc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["https://www.kaggle.com/code/edwardcrookenden/otto-getting-started-eda-baseline"],"metadata":{"id":"GBRGo2-Ee9_N"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"BcWAY4cnzu51"},"outputs":[],"source":["import pandas as pd\n","from pathlib import Path\n","import os\n","import numpy as np\n","import json\n","from datetime import timedelta\n","from collections import Counter\n","from tqdm.notebook import tqdm\n","from heapq import nlargest\n","\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import seaborn as sns\n","sns.set_theme()\n","\n"]},{"cell_type":"code","source":["#paths\n","\n","data_path = Path('../input/otto-recommender-system')\n","train = data_path/'train.jsonl'\n","test = data_path/'test.jsonl'\n","\n","sample_sub_path = Path('../input/otto-recommender-system/sample_submission.csv')"],"metadata":{"id":"AmvpbdnnfSif"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(train_path, 'r') as f :\n","  print(f'We have {len(f.readlines()):,} lines in the train data')"],"metadata":{"id":"kyivKyyCftEB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_size = 150000\n","\n","chunks = pd.read_json(train, lines=True, chunk=sample_size)\n","\n","for c in chunks :\n","  sample_train_df = c\n","  break\n"],"metadata":{"id":"FZWsz0YlfzP9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["기초적인 임플란트"],"metadata":{"id":"QJ-OeCMahZAY"}},{"cell_type":"code","source":["for e,chunk in enumerate(chunk) :\n","  event_dict = {'session':[], 'aid':[], 'ts' : [], 'type' : []}\n","\n","  if e < 2 :\n","    for session, events in zip(chunk['session'].tolist(), chunk['events'].tolist()) :\n","      for event in evnets :\n","        event_dict['session'].append(session)\n","        event_dict['aid'].append(event['aid'])\n","        event_dict['ts'].append(event['ts'])\n","        event_dict['type'].append(event['type'])\n","\n","    chunk_session = pd.DataFrame(event_dict)\n","    train = pd.concat([train, chunk_session])\n","  else :\n","    break\n","\n","\n","train = train.reset_index(drop=True)\n","\n","  "],"metadata":{"id":"87xmiI2SgA_8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_train_df.set_index(drop=True, inplace=True)\n"],"metadata":{"id":"fzirxyy9f738"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["DAta Structure"],"metadata":{"id":"VAKiy46FhbkQ"}},{"cell_type":"code","source":["#sample에서 맨 첫번째 row의 items 호출\n","example_session = sample_train_df.iloc[0].item()\n","\n","#time of session\n","time_elapsed = example_session[-1]['ts'] - example_session[0]['ts']\n","\n","# Count the freq of actions within the session\n","action_counts = {}\n","\n","for action in example_sesison :\n","  action_counts[action['type']] = action_counts.get(action['type'],0) +1\n","\n"],"metadata":{"id":"yaX3SdWLhV-k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Initial EDA"],"metadata":{"id":"LVBdP7FAhvFe"}},{"cell_type":"code","source":["action_counts_list, article_id_counts_list, session_length_time_list, session_length_action_list  = [[] for _ in range(4)]\n","\n","overall_action_counts = {}\n","overall_article_id_counts = {}\n","\n","for i,row in tqdm(sample_train_df.iterrows(), total=len(sample_train_df)) :\n","\n","  actions = row['events']\n","\n","  action_counts = {}\n","  article_id_counts = {}\n","\n","  for action in actions :\n","    action_counts[action['type']] = action_counts.get(action['type'],0) +1\n","\n","    article_id_counts[action['aid']] = article_id_counts.get(action['aid'], 0 ) +1\n","\n","    overall_action_counts[action['type']] = overall_action_counts.get(action['type'],0) +_1\n","    overall_article_id_counts[action['aid']] = overall_article_id_counts.get(action['aid'],0) +1\n","\n","  \n","  session_length_time = action[-1]['ts'] - action[0]['ts']\n","\n","  #add to list\n","\n","  action_counts_list,append(action_counts)\n","  article_id_counts_list.append(article_id_counts)\n","  session_length_time_list.append(session_length_time)\n","  session_length_action_list.append(len(actions))\n","\n","\n","sample_train_df['action_counts'] = action_counts_list\n","sample_train_df['article_id_counts'] =article_id_counts_list\n","sample_train_df['session_length_unix'] = session_length_time_list\n","sample_train_df['session_length_hours'] = sample_train_dp.session_length_unix*2.77778e-7\n","\n","sample_train_df['session_length_action'] = session_length_action_list\n"],"metadata":{"id":"Htv_IXPhhm63"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Actions \n","\n","total_actions = sum(overall_action_counts.values())\n","\n","plt.figure(figsize=(8,6))\n","\n","sns.barplot(x=list(overall_action_counts.keys()), y=[i/total_actions for i in overall_action_counts.values()])\n","\n","plt.title\n","plt.xlabel\n","plt.ylabel\n","plt.show()"],"metadata":{"id":"YpBH8IjfjeIP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots(1,2, figsize=(8,6))\n","\n","p=sns.distplot(sample_train_df['session_length_action'], color='y', bins=60, ax=ax[0], kde=False)\n","\n","p.set_xlabel('# actions')\n","p.set_ylabel('Density')\n","p.set_title('Dist of the # actions taken in each session')\n","\n","p.axvline(sample_train_df['session_length_action'].mean(), color='y', linestyle='--', label='mean')\n","\n","p=sns.distplot(sample_train_df['session_length_hours'])\n","p.set_xlabel('Hours')\n","p.set_ylabel('Density')\n","p.set_title('Lenth of each session')"],"metadata":{"id":"V6m1TNM0lUtj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f'{round(len(sample_train_df['session_length_action'] < 10) / len(sample_train_df),3)*100} % of the session had less than 10 actions')"],"metadata":{"id":"SL0pq6gel7gX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["article_id_freq = list(overall_article_id_counts.values())\n","\n","cut_off = [i for i in article_id_freq if i <35]\n","\n","plt.figure(figsize=(8,6))\n","sns.distplot(cut_off, bins=30, kde=FAlse)\n","\n","plt.title()\n","plt.xlabel()\n","plt.ylabel()\n","\n"],"metadata":{"id":"w57a8FsHmGiT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Look at the most interacted with articles\n","\n","print(f'Freq of most common articles : {sorted(list(overall_article_id_counts.values()))[-5]}')\n","\n","res = nlargest(5, overall_article_id_counts, keys=overall_article_id_counts.get)\n","\n","print(f'IDs for those common articles : {res}')"],"metadata":{"id":"ik0K1QULmWOZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Baseline\n","\n","The test data contrains truncated session data similar to that of the trainin gdata.\n","\n","The task is to predict the next aid clikced after the session truncation, as well as the remaining aids that are added to carts and orders ; you may predict up to 20 values for each session type\n","\n","Submissions are evalueate on Recall each action type, and the three recall value sare weight-averaged.\n","It is important ot get the 'orders' predictions correct as they carry most of the weighting\n","\n","For each session in the test data, your task it to predict the aid values for each type that occur after the last timestamp ts the test sseion. In other words, the test data contains sessions truncated by ts, and you are to predict what occurs after the point of truncation.\n","\n"],"metadata":{"id":"f5H7Haczmqix"}},{"cell_type":"code","source":["with open(test_path, 'r') as f :\n","  print(f'we have {len(f.readlines()):,} lines in the test data')"],"metadata":{"id":"ye8PrnMMmmJ7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_size = 150000\n","\n","chunks = pd.read_json(test_path, lines=True, chunk=sample_size)\n","\n","for c in chunks :\n","  sample_test_df = c\n","  break"],"metadata":{"id":"GeSPHSLSnUfq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_submission = pd.read_csv(sample_sub_path)\n"],"metadata":{"id":"ss5tbbZhncwj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_size = 150000\n","\n","chunks = pd.read_json(train, lines=True, chunk=sample_size)\n","\n","clikcs_article_list = []\n","carts_article_list = []\n","orders_article_list = []\n","\n","for e, c in enumerate(chunks) :\n","\n","  if e  >2 :\n","    break\n","  \n","  for i, row in c.iterrows() :\n","    actions = row['events']\n","    for action in actions :\n","      if aciton['type'] == 'clicks' :\n","        \n"],"metadata":{"id":"8DKlrXZengba"},"execution_count":null,"outputs":[]}]}